<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="utf-8" />
    
  <meta name="description" content="urlopen返回的response是一个HTTPResponse类型的对象，包含read(), readinto(), getheader(name), getheaders(), fileinto()等方法，以及msg, status, version, reason, debuglevel, closed等属性。" />
  
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1" />
  <title>
    urllib库的常用方法 |  梦开始的地方
  </title>
  <meta name="generator" content="hexo-theme-yilia-plus">
  
  <link rel="shortcut icon" href="/favicon.ico" />
  
  
<link rel="stylesheet" href="/css/style.css">

  
<script src="/js/pace.min.js"></script>


  

  

<link rel="alternate" href="/atom.xml" title="梦开始的地方" type="application/atom+xml">
</head>

</html>

<body>
  <div id="app">
    <main class="content">
      <section class="outer">
  <article id="post-urllib库的常用方法" class="article article-type-post" itemscope
  itemprop="blogPost" data-scroll-reveal>

  <div class="article-inner">
    
    <header class="article-header">
       
<h1 class="article-title sea-center" style="border-left:0" itemprop="name">
  urllib库的常用方法
</h1>
  

    </header>
    

    
    <div class="article-meta">
      <a href="/2018/12/10/urllib%E5%BA%93%E7%9A%84%E5%B8%B8%E7%94%A8%E6%96%B9%E6%B3%95/" class="article-date">
  <time datetime="2018-12-09T22:36:15.000Z" itemprop="datePublished">2018-12-10</time>
</a>
      
      
    </div>
    

    
    
    <div class="tocbot"></div>





    

    <div class="article-entry" itemprop="articleBody">
      


      

      
      <h2 id="发送请求"><a href="#发送请求" class="headerlink" title="发送请求"></a>发送请求</h2><h4 id="urlopen"><a href="#urlopen" class="headerlink" title="urlopen()"></a><strong><em>urlopen()</em></strong></h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">urllib.request.urlopen(url, data=<span class="literal">None</span>, [timeout, ]*, cafile=<span class="literal">None</span>, capath=<span class="literal">None</span>, cadefault=<span class="literal">False</span>, context=<span class="literal">None</span>)</span><br></pre></td></tr></table></figure>

<p>data参数：需要传递一个bytes()类型的数据，如果传递了这个参数，方法不再是GET，而变成了POST；如果要传递一个字典，则应该用urllib.parse模块的urlencode()函数编码</p>
<p>timeout参数：设置超时时间，超出这个时间没有响应就会抛出异常 </p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#GET请求方法</span></span><br><span class="line"><span class="keyword">import</span> urllib.request</span><br><span class="line"></span><br><span class="line">response = urllib.request.urlopen(<span class="string">'https://www.python.org'</span>)</span><br><span class="line">print(response.read().decode(<span class="string">'utf-8'</span>))</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#POST请求方法</span></span><br><span class="line"><span class="keyword">import</span> urllib.parse</span><br><span class="line"><span class="keyword">import</span> urllib.request</span><br><span class="line"></span><br><span class="line">data = bytes(urllib.parse.urlencode(&#123;<span class="string">"world"</span>: <span class="string">"hello"</span>&#125;), encoding=<span class="string">'utf8'</span>)</span><br><span class="line"></span><br><span class="line">response = urllib.request.urlopen(<span class="string">'http://httpbin.org/post'</span>, data=data)</span><br><span class="line">print(response.read())</span><br></pre></td></tr></table></figure>

<p><a href="http://httpbin.org" target="_blank" rel="noopener">http://httpbin.org</a></p>
<p>网站用来测试POST的数据</p>
<p>urlopen返回的response是一个HTTPResponse类型的对象，包含read(), readinto(), getheader(name), getheaders(), fileinto()等方法，以及msg, status, version, reason, debuglevel, closed等属性。</p>
<h6 id="常见status："><a href="#常见status：" class="headerlink" title="常见status："></a>常见status：</h6><table>
<thead>
<tr>
<th>代码</th>
<th>说明</th>
</tr>
</thead>
<tbody><tr>
<td>200</td>
<td>成功</td>
</tr>
<tr>
<td>400</td>
<td>错误请求</td>
</tr>
<tr>
<td>404</td>
<td>未找到</td>
</tr>
<tr>
<td>405</td>
<td>方法禁用</td>
</tr>
<tr>
<td>500</td>
<td>服务器内部错误</td>
</tr>
</tbody></table>
<h4 id="Request"><a href="#Request" class="headerlink" title="Request"></a><strong><em>Request</em></strong></h4><p>若请求中需要加入Headers等信息，可以利用Request类来构建。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">urllib</span>.<span class="title">request</span>.<span class="title">Request</span><span class="params">(url, data=None, headers=&#123;&#125;, origin_req_host=None, unverifiable=False, method=None)</span></span></span><br></pre></td></tr></table></figure>

<p>headers参数用于添加请求头，可以直接在构造时通过headers参数直接构造，也可以调用请求实例的add_header()方法添加；添加请求头最常见的是修改User-Agent来伪装浏览器</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#GET请求方法</span></span><br><span class="line"><span class="keyword">import</span> urllib.request</span><br><span class="line"></span><br><span class="line">request = urllib.request.Request(<span class="string">'https://python.org'</span>)</span><br><span class="line">response = urllib.request.urlopen(request)</span><br><span class="line">print(response.read().decode(<span class="string">'utf-8'</span>))</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#POST请求方法</span></span><br><span class="line"><span class="keyword">import</span> urllib.parse</span><br><span class="line"><span class="keyword">import</span> urllib.request</span><br><span class="line"></span><br><span class="line">url = <span class="string">'http://httpbin.org/post'</span></span><br><span class="line">headers = &#123;</span><br><span class="line">    <span class="string">'User-Agent'</span>: <span class="string">'Mozilla/4.0 (compatible;MSIE 5.5; Windows NT)'</span>,</span><br><span class="line">    <span class="string">'Host'</span>: <span class="string">'httpbin.org'</span></span><br><span class="line">&#125;</span><br><span class="line">dict = &#123;</span><br><span class="line">    <span class="string">'name'</span>: <span class="string">'Jerry'</span></span><br><span class="line">&#125;</span><br><span class="line">data = bytes(parse.urlencode(dict), encoding=<span class="string">'utf8'</span>)</span><br><span class="line"></span><br><span class="line">req = request.Request(url=url, data=data, headers=headers, method=<span class="string">'POST'</span>)</span><br><span class="line">response = request.urlopen(req)</span><br><span class="line">print(response.read().decode(<span class="string">'utf-8'</span>))</span><br></pre></td></tr></table></figure>

<h6 id="高级用法："><a href="#高级用法：" class="headerlink" title="高级用法："></a>高级用法：</h6><p>引入OpenerDirector和Handler类来实现高级功能，如处理HTTP响应错误、处理重定向、处理cookies、设置代理、管理密码等。</p>
<p>思路：用Handler来构建Opener</p>
<p>例1：处理验证</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> urllib.request <span class="keyword">import</span> HTTPPasswordMgrWithDefaultRealm, HTTPBasicAuthHandler, build_opener</span><br><span class="line"><span class="keyword">from</span> urllib.error <span class="keyword">import</span> URLError</span><br><span class="line"></span><br><span class="line">username = <span class="string">'username'</span></span><br><span class="line">password = <span class="string">'password'</span></span><br><span class="line">url = <span class="string">'http://localhost:8080/'</span></span><br><span class="line"></span><br><span class="line">p = HTTPPasswordMgrWithDefaultRealm()</span><br><span class="line">p.add_password(<span class="literal">None</span>, url, username, password)</span><br><span class="line">auth_handler = HTTPBasicAuthHandler(p)</span><br><span class="line">opener = build_opener(auth_handler)</span><br></pre></td></tr></table></figure>

<p>例2：设置代理</p>
<p>这里我们在本机9743端口搭建了一个代理，下面使用这个代理进行url访问</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> urllib.request <span class="keyword">import</span> ProxyHandler, build_opener</span><br><span class="line"><span class="keyword">from</span> urllib.error <span class="keyword">import</span> URLError</span><br><span class="line"></span><br><span class="line">proxy_handler = ProxyHandler(&#123;</span><br><span class="line">    <span class="string">'http'</span>: <span class="string">'http://127.0.0.1:9743'</span>,</span><br><span class="line">    <span class="string">'https'</span>: <span class="string">'https://127.0.0.1:9743'</span></span><br><span class="line">&#125;)</span><br><span class="line">opener = build_opener(proxy_handler)</span><br><span class="line"><span class="keyword">try</span>:</span><br><span class="line">    response = opener.open(<span class="string">'https://www.baidu.com'</span>)</span><br><span class="line">    print(response.read().decode(<span class="string">'utf-8'</span>))</span><br><span class="line"><span class="keyword">except</span> URLError <span class="keyword">as</span> e:</span><br><span class="line">    print(e.reason)</span><br></pre></td></tr></table></figure>

<p>例3：获取网站的Cookies</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> http.cookiejar, urllib.request</span><br><span class="line"></span><br><span class="line">cookie = http.cookiejar.CookieJar()</span><br><span class="line">handler = urllib.request.HTTPCookieProcessor(cookie)</span><br><span class="line">opener = urllib.request.build_opener(handler)</span><br><span class="line">response = opener.open(<span class="string">'http://www.baidu.com'</span>)</span><br><span class="line"><span class="keyword">for</span> item <span class="keyword">in</span> cookie:</span><br><span class="line">    print(item.name + <span class="string">" = "</span> + item.value)</span><br></pre></td></tr></table></figure>

<p>若要将cookie存入文件中，则需要将CookieJar换为MozillaCookieJar(后者是前者的子类)，或者换为LWPCookieJar，二者格式不同，效果相似。</p>
<hr>
<h2 id="处理异常"><a href="#处理异常" class="headerlink" title="处理异常"></a>处理异常</h2><h4 id="URLError"><a href="#URLError" class="headerlink" title="URLError"></a><strong><em>URLError</em></strong></h4><p>URLError类来自urllib库的error模块，继承自OSError类，是error异常模块的基类，由request模块发生的异常都可以通过捕获这个类来处理。具有一个reason返回错误原因</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> urllib <span class="keyword">import</span> request, error</span><br><span class="line"><span class="keyword">try</span>:</span><br><span class="line">    response = request.urlopen(<span class="string">'https://luhao.com/index.html'</span>)</span><br><span class="line">    <span class="keyword">except</span> error.URLError <span class="keyword">as</span> e:</span><br><span class="line">        print(e.reason)</span><br></pre></td></tr></table></figure>

<h4 id="HTTPError"><a href="#HTTPError" class="headerlink" title="HTTPError"></a><strong><em>HTTPError</em></strong></h4><p>是URLError的子类，专门用来处理HTTP请求错误，有三个属性：code返回HTTP状态码；reason返回错误信息；headers返回请求头。</p>
<h2 id="解析链接"><a href="#解析链接" class="headerlink" title="解析链接"></a>解析链接</h2><h4 id="urlparse"><a href="#urlparse" class="headerlink" title="urlparse()"></a><strong><em>urlparse()</em></strong></h4><p>实现url的识别和分段，有三个参数：urlstring（必填，是待解析的url），scheme（指定默认协议），allow_fragments（是否忽略fragment，若设置为false，fragment部分会被解析为path，params， query的一部分）</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">标准的url格式：</span><br><span class="line">scheme:&#x2F;&#x2F;netloc&#x2F;path;params?query#fragment</span><br></pre></td></tr></table></figure>



<h4 id="urlunparse"><a href="#urlunparse" class="headerlink" title="urlunparse()"></a><strong><em>urlunparse()</em></strong></h4><p>实现URL的构造，接受6个参数，不能多也不能少。当然也可以把六个参数构造为列表、元组等形式再传给urlunparse()</p>
<h4 id="urlsplit"><a href="#urlsplit" class="headerlink" title="urlsplit()"></a><strong><em>urlsplit()</em></strong></h4><p>与urlparse()类似，不同的是它只接受5个参数，不再单独解析params这一部分，params会合并到path中</p>
<h4 id="urlunsplit"><a href="#urlunsplit" class="headerlink" title="urlunsplit()"></a><strong><em>urlunsplit()</em></strong></h4><p>与urlunparse()类似，不同的是它只接受5个参数</p>
<h4 id="urljoin"><a href="#urljoin" class="headerlink" title="urljoin()"></a><strong><em>urljoin()</em></strong></h4><p>有base_url作为第一个参数，新的链接作为第二个参数。base_url提供scheme、netloc、path三项内容，若新链接里不存在这三项，则使用base_url中的部分；若存在则使用新连接的部分</p>
<h4 id="urlencode"><a href="#urlencode" class="headerlink" title="urlencode()"></a><strong><em>urlencode()</em></strong></h4><p>可以将一个字典序列化为GET请求参数</p>
<h4 id="parse-qs"><a href="#parse-qs" class="headerlink" title="parse_qs()"></a><strong><em>parse_qs()</em></strong></h4><p>可以将一串GET请求参数反序列化为一个字典</p>
<h4 id="parse-qsl"><a href="#parse-qsl" class="headerlink" title="parse_qsl()"></a><strong><em>parse_qsl()</em></strong></h4><p>用于将GET请求参数转化为元组组成的列表，每个元组的第一个元素是参数名，第二个元素是参数值</p>
<h4 id="quote"><a href="#quote" class="headerlink" title="quote()"></a><strong><em>quote()</em></strong></h4><p>可以将内容转化为URL编码的格式，当URL中带有中文时，可以使用这个方法将中文字符转化为URL编码</p>
<h4 id="unquote"><a href="#unquote" class="headerlink" title="unquote()"></a><strong><em>unquote()</em></strong></h4><p>可以对URL进行解码</p>
<h2 id="分析Robots协议"><a href="#分析Robots协议" class="headerlink" title="分析Robots协议"></a>分析Robots协议</h2><p>robots.txt样例：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">User-agent:*</span><br><span class="line">Disallow: &#x2F;</span><br><span class="line">Allow: &#x2F;public&#x2F;</span><br></pre></td></tr></table></figure>

<p>其中User-agent用来指定该网站允许哪些爬虫，Disallow和Allow一般成对出现，一个指定不允许爬虫的网页，一个指定允许爬的网页。</p>
<h4 id=""><a href="#" class="headerlink" title=""></a></h4>
      
      <!-- 打赏 -->
      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2018/12/10/urllib%E5%BA%93%E7%9A%84%E5%B8%B8%E7%94%A8%E6%96%B9%E6%B3%95/" data-id="ck5kv0nax00032su44fme5uvn"
        class="article-share-link">分享</a>
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/python-spider/" rel="tag">python spider</a></li></ul>

    </footer>

  </div>

  
  
  <nav class="article-nav">
    
      <a href="/2018/12/19/Spring-boot-Vue%E8%A7%A3%E5%86%B3%E8%B7%A8%E5%9F%9F%E9%97%AE%E9%A2%98/" class="article-nav-link">
        <strong class="article-nav-caption">上一篇</strong>
        <div class="article-nav-title">
          
            Spring boot + Vue解决跨域问题
          
        </div>
      </a>
    
    
  </nav>


  

  

  
  
  

</article>
</section>
      <footer class="footer">
  <div class="outer">
    <ul class="list-inline">
      <li>
        &copy;
        2015-2020
        Kirby Hao
      </li>
      <li>
        
          Powered by
        
        
        <a href="https://hexo.io" target="_blank">Hexo</a> Theme <a href="https://github.com/Shen-Yu/hexo-theme-ayer" target="_blank">Ayer</a>
        
      </li>
    </ul>
    <ul class="list-inline">
      <li>
        
      </li>
      <li>
        <!-- cnzz统计 -->
        
      </li>
    </ul>
  </div>
</footer>
    <div class="to_top">
        <div class="totop" id="totop">
  <i class="ri-arrow-up-line"></i>
</div>
      </div>
    </main>
    
    <aside class="sidebar">
      
        <button class="navbar-toggle"></button>
<nav class="navbar">
  
  <div class="logo">
    <a href="/"><img src="/images/ayer-side.svg" alt="梦开始的地方"></a>
  </div>
  
  <ul class="nav nav-main">
    
    <li class="nav-item">
      <a class="nav-item-link" href="/">主页</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/archives">目录</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/tags">标签</a>
    </li>
    
  </ul>
</nav>
<nav class="navbar navbar-bottom">
  <ul class="nav">
    <li class="nav-item">
      
      <a class="nav-item-link nav-item-search"  title="Search">
        <i class="ri-search-line"></i>
      </a>
      
      
      <a class="nav-item-link" target="_blank" href="/atom.xml" title="RSS Feed">
        <i class="ri-rss-line"></i>
      </a>
      
    </li>
  </ul>
</nav>
<div class="search-form-wrap">
  <div class="local-search local-search-plugin">
  <input type="search" id="local-search-input" class="local-search-input" placeholder="Search...">
  <div id="local-search-result" class="local-search-result"></div>
</div>
</div>
      </aside>
      <div id="mask"></div>

<!-- #reward -->
<div id="reward">
  <span class="close"><i class="ri-close-line"></i></span>
  <p class="reward-p"><i class="ri-cup-line"></i></p>
  <div class="reward-box">
    
    
  </div>
</div>
      
<script src="/js/jquery-2.0.3.min.js"></script>


<script src="/js/jquery.justifiedGallery.min.js"></script>


<script src="/js/lazyload.min.js"></script>


<script src="/js/busuanzi-2.3.pure.min.js"></script>


  
<script src="/fancybox/jquery.fancybox.min.js"></script>




  
<script src="/js/tocbot.min.js"></script>

  <script>
    // Tocbot_v4.7.0  http://tscanlin.github.io/tocbot/
    tocbot.init({
      tocSelector: '.tocbot',
      contentSelector: '.article-entry',
      headingSelector: 'h1, h2, h3, h4, h5, h6',
      hasInnerContainers: true,
      scrollSmooth: true,
      positionFixedSelector: '.tocbot',
      positionFixedClass: 'is-position-fixed',
      fixedSidebarOffset: 'auto',
			onClick: (e) => {
      	document.getElementById(e.target.innerText).scrollIntoView()
      	return false;
    	}
    });
  </script>


<script>
  var ayerConfig = {
    mathjax: false
  }
</script>


<script src="/js/ayer.js"></script>


<script src="https://cdn.jsdelivr.net/npm/jquery-modal@0.9.2/jquery.modal.min.js"></script>
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/jquery-modal@0.9.2/jquery.modal.min.css">



<script type="text/javascript" src="https://js.users.51.la/20544303.js"></script>
  
  

  </div>
</body>

</html>